% Discrete Cosine Transform
% Jon Craton

[![Build Status](https://travis-ci.org/jncraton/discrete-cosine-transform.svg?branch=master)](https://travis-ci.org/jncraton/discrete-cosine-transform) 
[![GitHub last commit](https://img.shields.io/github/last-commit/jncraton/discrete-cosine-transform.svg)](https://github.com/jncraton/simulated-annealing)

The discrete cosine transform is a common algorithm in video and image compression. It serves as the core of the JPEG compression algorithm and is also present in many other modern compression standards such as the MPEG standards, Theora, and AV1.[2]

The discrete cosine transform comes in many types, the most common of which is DCT Type 2.[3] That is the type used in JPEG and the type that we will explore here.

The DCT Type-2 is represented by the following mathematical formula[4]:

$X_k = 2 \sum_{n=0}^{N-1} x_n \cos \left[\frac{\pi}{N} \left(n+\frac{1}{2}\right) k \right] \quad \quad k = 0, \dots, N-1.$

This DCT may be formulated using scale factors other than 2, but we'll implement it using a scale factor of 2 as in that paper.

Brute Force Algorithm
=====================

Here is the formula as Python code:

```python
import math
from math import pi
from random import random
from scipy.fftpack import dct as ref_dct
import numpy as np

def dct(x, cos=math.cos):
  """
  Return a Type-2 Discrete cosine transform of list x

  >>> round(dct(range(0,64))[0], 2)
  4032.0
  >>> round(dct(range(0,64))[-1], 2)
  -0.02
  >>> round(dct(range(128,256,2))[0], 2)
  24448.0
  >>> round(dct(range(128,256,2))[-1], 2)
  -0.05

  Let's test against the numpy implementation
  >>> np.allclose(dct(range(0,64)), ref_dct(range(0,64)))
  True
  >>> np.allclose(dct(range(128,256,2)), ref_dct(range(128,256,2)))
  True
  >>> rand_512 = [random() for r in range(0,1024)]
  >>> np.allclose(dct(rand_512), ref_dct(rand_512))
  True
  """
  
  N = len(x)
  r = range(0,N)
  return [2*sum(x[n]*cos((pi/N)*(n+.5)*k) for n in r) for k in r]
``` 

If we wanted a more procedural approach, this could also be coded as follows:

```python
def procedural_dct(x):
  """
  >>> np.allclose(procedural_dct(range(128,256,2)), ref_dct(range(128,256,2)))
  True
  """
    
  N = len(x)
  r = range(0,N)

  def summand(xk, k, n, N):
    return xk * math.cos( (pi/N) * (n + .5) * k )

  ret = []

  for k in r:
    sum = 0
    for n in r:
      sum += summand(x[n], k, n, N)
    ret.append(2*sum)

  return ret
```

Correctness
-----------

We can see that we've directly implemented the mathematical formula for DCT in our code. We simply perform the specified summation for each element in our array. This is an obviously correct implementation.

I've also included several embedded doctest in the Python function to test our function against some reference values and against the DCT implementation in numpy.

Performance
-----------

This algorithm clearly has O(n²) performance. Our function returns a nested generator over our range. Because there are 2 nested generators, we see that the math in our summation is executed exactly n² times. This shows that the best-case, worst-case, and average-case performance is always n².

We can also show this with empiracle testing. Let's first check performance by counting calls to cos for various input matrix sizes.

```python
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()

def cos_count(x):
  cos_count.count += 1
  return math.cos(x)

results = []

for i in range (1,17):
  cos_count.count = 0
  dct(range(0,i**2),cos_count)
  print("%dx%d: %d calls" % (i,i,cos_count.count))
  results.append((i**2,cos_count.count))
```

And let's create a plot of the results:

```python,results="hidden"
plt.plot([r[0] for r in results], [r[1] for r in results])
plt.xlabel('Matrix size (total items)')
plt.ylabel('Summand evaluations')
plt.title('Summand evaluations vs input size')
```

We can see that these are the exact n² results that we predicted. We can also measure actual runtime:

```python
from time import process_time

results = []

for i in range (1,17):
  start = process_time()
  for _ in range(0,10):
    dct(range(0,i**2))
  ms = (process_time() - start)*100
  print("%dx%d: %.02fms" % (i,i,ms))
  results.append((i**2,ms))
```

And the plotted runtime:

```python,results="hidden"
plt.plot([r[0] for r in results], [r[1] for r in results])
plt.xlabel('Matrix size (total items)')
plt.ylabel('Runtime (ms)')
plt.title('Runtime vs input size')
```

Quasi-Linear Implementation
===========================

We can significantly improve the performance of our algorithm by implementing a variation of the Cooley-Tukey algorithm. This algorithm is usually used for optimized Fourier transforms, but we can apply to our case as well. 

Correctness
-----------

We're looking for a way to split our list in half and operate on the halves independently to bring our performance down from O(n²) to O(n log n).

Before we implement an algorithm, let's prove mathematically that we have one that is correct. First, let's look at this version of the DCT that shows its relationship to an FFT:



Consider the following generic definition for the discrete Fourier transform:

$X_k = \sum_{n=0}^{N-1} x_n e^{-\frac{2\pi i}{N} nk}$

We can break this sum in the sum of two sums, each over half of the elements of the original (radix-2 decimation-in-time method)[5]:

$\begin{matrix} X_k & =
& \sum \limits_{m=0}^{N/2-1} x_{2m}e^{-\frac{2\pi i}{N} (2m)k}   +   \sum \limits_{m=0}^{N/2-1} x_{2m+1} e^{-\frac{2\pi i}{N} (2m+1)k}
  \end{matrix}$

$\begin{matrix} X_k= \underbrace{\sum \limits_{m=0}^{N/2-1} x_{2m}   e^{-\frac{2\pi i}{N/2} mk}}_{\mathrm{DFT\;of\;even-indexed\;part\;of\;} x_n} {} +  e^{-\frac{2\pi i}{N}k}
 \underbrace{\sum \limits_{m=0}^{N/2-1} x_{2m+1} e^{-\frac{2\pi i}{N/2} mk}}_{\mathrm{DFT\;of\;odd-indexed\;part\;of\;} x_n} =  E_k + e^{-\frac{2\pi i}{N}k} O_k.
\end{matrix}$

Implementation
--------------

Here's our Fourier transform algorithm as psuedocode[5][7]:

    X0,...,N−1 ← ditfft2(x, N, s):             DFT of (x0, xs, x2s, ..., x(N-1)s):
        if N = 1 then
            X0 ← x0                                      trivial size-1 DFT base case
        else
            X0,...,N/2−1 ← ditfft2(x, N/2, 2s)             DFT of (x0, x2s, x4s, ...)
            XN/2,...,N−1 ← ditfft2(x+s, N/2, 2s)           DFT of (xs, xs+2s, xs+4s, ...)
            for k = 0 to N/2−1                           combine DFTs of two halves into full DFT:
                t ← Xk
                Xk ← t + exp(−2πi k/N) Xk+N/2
                Xk+N/2 ← t − exp(−2πi k/N) Xk+N/2
            endfor
        endif

And here it is implemented in Python:

```python
from scipy.fftpack import fft as ref_fft

def fft(x):
  """
  >>> np.allclose(fft(list(range(0,64))), ref_fft(range(0,64)))
  True
  >>> np.allclose(fft(list(range(128,256,2))), ref_fft(range(128,256,2)))
  True
  >>> rand_512 = [random() for r in range(0,1024)]
  >>> np.allclose(fft(rand_512), ref_fft(rand_512))
  True
  """
  N=len(x)
  
  if N < 2:
    return x

  x = fft(x[0:][::2]) + fft(x[1:][::2])

  for k in range(int(N/2)):
    e = x[k]
    o = x[k+int(N/2)]
    w = math.e ** (-2j*pi*k/N )
    x[k] = e + w * o
    x[k+int(N/2)] = e - w * o

  return x
```

Now we can use our FFT to compute a DCT using Makhoul:

```python
def makhoul_dct(x):
  """
  Return a Type-2 Discrete cosine transform of list x

  >>> round(makhoul_dct(list(range(0,64)))[0], 2)
  4032.0
  >>> round(makhoul_dct(list(range(0,64)))[-1], 2)
  -0.02
  >>> round(makhoul_dct(list(range(128,256,2)))[0], 2)
  24448.0
  >>> round(makhoul_dct(list(range(128,256,2)))[-1], 2)
  -0.05

  Let's test against the numpy implementation
  >>> np.allclose(makhoul_dct(list(range(0,64))), ref_dct(range(0,64)))
  True
  >>> np.allclose(makhoul_dct(list(range(128,256,2))), ref_dct(range(128,256,2)))
  True
  >>> rand_512 = [random() for r in range(0,1024)]
  >>> np.allclose(makhoul_dct(rand_512), ref_dct(rand_512))
  True
  """
  t = fft(x + x[::-1])[:len(x)]

  return [(i * math.e ** (-1j*pi*(k/(2*len(x))))).real for k,i in enumerate(t)]
```

Performance
-----------

```python
from time import process_time

fft_results = []

for i in range (1,7):
  i = 2**i
  start = process_time()
  for _ in range(0,10):
    makhoul_dct(list(range(0,i**2)))
  ms = (process_time() - start)*100
  print("%dx%d: %.02fms" % (i,i,ms))
  fft_results.append((i**2,ms))
```

And the plotted runtime:

```python,results="hidden"
plt.plot([r[0] for r in fft_results], [r[1] for r in fft_results],label="Cooley-Tukey")
plt.plot([r[0] for r in results], [r[1] for r in results],label="Naive")
plt.xlabel('Matrix size (total items)')
plt.ylabel('Runtime (ms)')
plt.title('Runtime vs input size')
plt.legend()
```


References
==========

1. https://en.wikipedia.org/wiki/Discrete_cosine_transform
2. https://en.wikipedia.org/wiki/AV1
3. https://github.com/scipy/scipy/blob/v1.1.0/scipy/fftpack/realtransforms.py#L263-L377
4. A Fast Cosine Transform in One and Two Dimensions, by J. Makhoul, IEEE Transactions on acoustics, speech and signal processing vol. 28(1), pp. 27-34, http://dx.doi.org/10.1109/TASSP.1980.1163351 (1980). http://eelinux.ee.usm.maine.edu/courses/ele486/docs/makhoul.fastDCT.pdf
5. https://en.wikipedia.org/wiki/Cooley–Tukey_FFT_algorithm
6  Cooley, James W.; Tukey, John W. (1965). "An algorithm for the machine calculation of complex Fourier series". Math. Comput. 19: 297–301. doi:10.2307/2003354.
7. S. G. Johnson and M. Frigo, "Implementing FFTs in practice," in Fast Fourier Transforms (C. S. Burrus, ed.), ch. 11, Rice University, Houston TX: Connexions, September 2008.
8. https://dsp.stackexchange.com/questions/2807/fast-cosine-transform-via-fft
           